{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to <code>cuallee</code> and thanks for using this amazing framework. None of this work could have been possible without the inspiration of <code>pydeequ</code>. So, thanks to the AWS folks for putting the research work together, and the references so that we could build on the shoulders of giants.</p> <p>This <code>pure-python</code> implementation of unit tests for your data, will help you define validations for your data using <code>3</code> concepts described below:</p>"},{"location":"#entities","title":"Entities","text":"<p>To better understand <code>cuallee</code> you will need to get familiar with the following 3 concepts: <code>Check</code>, <code>Rule</code> and <code>ComputeInstruction</code>. </p> Entity Icon Description <code>Check</code> Use it to define a group of validations on a <code>dataframe</code> and report them as <code>WARNING</code> or <code>ERROR</code>. You can chain as many rules into a <code>check</code>, internally <code>cuallee</code> will make sure the same rule is not executed twice. <code>Rule</code> A <code>rule</code> represents the predicate you want to test on a <code>single</code> or <code>multiple</code> columns in a dataframe. A rule as a 4 attributes <code>method</code>: name of the predicate, <code>column</code>: the column in the dataframe, <code>value</code>: the value to compare against and <code>coverage</code>: the percentage of positive predicate necessary to set the status of the check to <code>PASS</code>. <code>ComputeInstruction</code> Are the implementation specific representations of the <code>predicates</code> in the <code>rule</code>. Because <code>cuallee</code> is a dataframe agnostic data quality framework, the implementation of the rules, rely in the creation of compute instructions passed to the specific dataframe of choice, including the following dataframe options: <code>pandas</code>, <code>pyspark</code> and <code>snowpark</code> <p>In principle, the only interface you need to be familiar with is the <code>Check</code> as it is through this <code>object</code> that you can chain your validations and then directly through the <code>validate</code> method, execute validations on any <code>DataFrame</code>.</p>"},{"location":"#process-flow","title":"Process Flow","text":"<pre><code>graph LR\n  U((start)) --&gt; A;\n  A[Check] -.-&gt; B(is_complete);\n  A[Check] -.-&gt; C(is_between);\n  A[Check] -.-&gt; D(is_on_weekday);\n  B --&gt; E{all rules?};\n  C --&gt; E{all rules?};\n  D --&gt; E{all rules?};\n  E --&gt; F[/read dataframe/];\n  A -.-&gt; G{want results?};\n  F --&gt; G;\n  G --&gt; H(validate);\n  H --&gt; I([get results])\n  I --&gt; K((end))\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p><code>cuallee</code> is designed to work primarily with <code>pyspark==3.3.0</code> and this is its only dependency. It uses the <code>Observation</code> API features in pyspark, to reduce the computation time for aggregations, and calculating summaries in one pass of the data frames being validated.</p>"},{"location":"#pip","title":"pip","text":"<pre><code># Latest\npip install cuallee\n</code></pre>"},{"location":"#check","title":"Check","text":"<p>Validating data sets is about creating a <code>Check</code> and adding rules into it. You can choose from different types: <code>numeric</code>, <code>date algebra</code>, <code>range of values</code>, <code>temporal</code>, and many others.</p> <p>A <code>Check</code> provides a declarative interface to build a comprehensive validation on a dataframe as shown below:</p> <pre><code># Imports\nfrom cuallee import Check, CheckLevel\nfrom cuallee import dataframe as D\n\n# Check \ncheck = Check(CheckLevel.WARNING, \"TaxiNYCheck\")\n\n# Data\ndf = spark.read.parquet(\"temp/taxi/*.parquet\")\n\n# Adding rules\n# =============\n\n # All fields are filled\n[check.is_complete(name) for name in df.columns]\n\n# Verify taxi ride distance is positive\n[check.is_greater_than(name, 0) for name in D.numeric_fields(df)] \n\n# Confirm that tips are not outliers\n[check.is_less_than(name, 1e4) for name in D.numeric_fields(df)] \n\n# 70% of data is on weekdays\n[check.is_on_weekday(name, .7) for name in D.timestamp_fields(df)] \n\n# Binary classification fields\n[check.has_entropy(name, 1.0, 0.5) for name in D.numeric_fields(df)] \n\n# Percentage of big tips\n[check.is_between(name, (1000,2000)) for name in D.numeric_fields(df)] \n\n# Confirm 22 years of data\n[check.is_between(name, (\"2000-01-01\", \"2022-12-31\")) for name in D.timestamp_fields(df)]\n\n# Validation\ncheck.validate(df)\n</code></pre>"},{"location":"advanced/","title":"Advanced Checks","text":""},{"location":"advanced/#satisfies","title":"satisfies","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> satisfies simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"advanced/#has_entropy","title":"has_entropy","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_entropy simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"advanced/#has_weekday_continuity","title":"has_weekday_continuity","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_weekday_continuity simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"dependencies/","title":"Dependencies","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"new-check/","title":"New Check","text":""},{"location":"validate/","title":"validate","text":""},{"location":"pandas/","title":"Check","text":""},{"location":"pandas/#pandas","title":"pandas","text":""},{"location":"pandas/#is_complete","title":"is_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#are_complete","title":"are_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_unique","title":"is_unique","text":"<p>This check verifies that the number of distinct values for a column is equal to the number of rows of the dataframe.</p> is_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#are_unique","title":"are_unique","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_greater_than","title":"is_greater_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_greater_or_equal_than","title":"is_greater_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_less_than","title":"is_less_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_less_or_equal_than","title":"is_less_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_equal_than","title":"is_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_pattern","title":"has_pattern","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_pattern simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_min","title":"has_min","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_max","title":"has_max","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_std","title":"has_std","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_std simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_mean","title":"has_mean","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_mean simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_between","title":"is_between","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_between simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_contained_in","title":"is_contained_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_contained_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_in","title":"is_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_weekday","title":"is_on_weekday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_weekend","title":"is_on_weekend","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekend simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_monday","title":"is_on_monday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_monday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_tuesday","title":"is_on_tuesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_tuesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_wednesday","title":"is_on_wednesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_wednesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_thursday","title":"is_on_thursday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_thursday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_friday","title":"is_on_friday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_friday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_saturday","title":"is_on_saturday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_saturday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_sunday","title":"is_on_sunday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_sunday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#is_on_schedule","title":"is_on_schedule","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_schedule simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_percentile","title":"has_percentile","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_percentile simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_max_by","title":"has_max_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_min_by","title":"has_min_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pandas/#has_correlation","title":"has_correlation","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_correlation simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/","title":"Check","text":""},{"location":"pyspark/#pyspark","title":"pyspark","text":""},{"location":"pyspark/#is_complete","title":"is_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#are_complete","title":"are_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_unique","title":"is_unique","text":"<p>This check verifies that the number of distinct values for a column is equal to the number of rows of the dataframe.</p> is_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#are_unique","title":"are_unique","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_greater_than","title":"is_greater_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_greater_or_equal_than","title":"is_greater_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_less_than","title":"is_less_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_less_or_equal_than","title":"is_less_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_equal_than","title":"is_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_pattern","title":"has_pattern","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_pattern simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_min","title":"has_min","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_max","title":"has_max","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_std","title":"has_std","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_std simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_mean","title":"has_mean","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_mean simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_between","title":"is_between","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_between simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_contained_in","title":"is_contained_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_contained_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_in","title":"is_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_weekday","title":"is_on_weekday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_weekend","title":"is_on_weekend","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekend simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_monday","title":"is_on_monday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_monday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_tuesday","title":"is_on_tuesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_tuesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_wednesday","title":"is_on_wednesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_wednesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_thursday","title":"is_on_thursday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_thursday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_friday","title":"is_on_friday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_friday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_saturday","title":"is_on_saturday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_saturday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_sunday","title":"is_on_sunday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_sunday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#is_on_schedule","title":"is_on_schedule","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_schedule simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_percentile","title":"has_percentile","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_percentile simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_max_by","title":"has_max_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_min_by","title":"has_min_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"pyspark/#has_correlation","title":"has_correlation","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_correlation simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/","title":"Check","text":""},{"location":"snowpark/#snowpark","title":"snowpark","text":""},{"location":"snowpark/#is_complete","title":"is_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#are_complete","title":"are_complete","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_complete simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_unique","title":"is_unique","text":"<p>This check verifies that the number of distinct values for a column is equal to the number of rows of the dataframe.</p> is_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#are_unique","title":"are_unique","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> are_unique simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_greater_than","title":"is_greater_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_greater_or_equal_than","title":"is_greater_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_greater_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_less_than","title":"is_less_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_less_or_equal_than","title":"is_less_or_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_less_or_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_equal_than","title":"is_equal_than","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_equal_than simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_pattern","title":"has_pattern","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_pattern simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_min","title":"has_min","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_max","title":"has_max","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_std","title":"has_std","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_std simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_mean","title":"has_mean","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_mean simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_between","title":"is_between","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_between simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_contained_in","title":"is_contained_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_contained_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_in","title":"is_in","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_in simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_weekday","title":"is_on_weekday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_weekend","title":"is_on_weekend","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_weekend simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_monday","title":"is_on_monday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_monday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_tuesday","title":"is_on_tuesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_tuesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_wednesday","title":"is_on_wednesday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_wednesday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_thursday","title":"is_on_thursday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_thursday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_friday","title":"is_on_friday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_friday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_saturday","title":"is_on_saturday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_saturday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_sunday","title":"is_on_sunday","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_sunday simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#is_on_schedule","title":"is_on_schedule","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> is_on_schedule simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_percentile","title":"has_percentile","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_percentile simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_max_by","title":"has_max_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_max_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_min_by","title":"has_min_by","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_min_by simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"},{"location":"snowpark/#has_correlation","title":"has_correlation","text":"<p>This check is the most popular. It validates the completeness attribute of a data set. It confirms that all fields contain values different of <code>null</code>.</p> has_correlation simplecoverage <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"CompletePredicate\")\ncheck.is_complete(\"id\")\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |1.0           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre> <pre><code>from cuallee import Check, CheckLevel\ndf = spark.range(10)\ncheck = Check(CheckLevel.WARNING, \"IsComplete\")\ncheck.is_complete(\"id\", .5) # Only 50% coverage\n\n# Validate\ncheck.validate(spark, df).show(truncate=False)\n</code></pre> <p>Result:</p> <pre><code>+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|id |timestamp          |check            |level  |column|rule       |value|rows|violations|pass_rate|pass_threshold|metadata|status|\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n|1  |2022-10-09 23:45:10|CompletePredicate|WARNING|id    |is_complete|N/A  |10  |0         |1.0      |0.5           |{}      |PASS  |\n+---+-------------------+-----------------+-------+------+-----------+-----+----+----------+---------+--------------+--------+------+\n</code></pre>"}]}